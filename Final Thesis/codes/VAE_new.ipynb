{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tried to convert 'x' to a tensor and failed. Error: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m vae\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mvae_loss)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Train the VAE model\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust epochs as needed\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Calculate reconstruction loss for anomaly detection\u001b[39;00m\n\u001b[1;32m     68\u001b[0m reconstructed \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mpredict(features_scaled)\n",
      "File \u001b[0;32m~/apps/source/develop/lab-master/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[9], line 53\u001b[0m, in \u001b[0;36mvae_loss\u001b[0;34m(inputs, x_decoded_mean)\u001b[0m\n\u001b[1;32m     50\u001b[0m reconstruction_loss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m input_dim  \u001b[38;5;66;03m# Scale by input dimension to match overall scale\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# KL divergence loss\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m kl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m K\u001b[38;5;241m.\u001b[39msum(\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_mean\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m K\u001b[38;5;241m.\u001b[39mexp(z_log_var) \u001b[38;5;241m-\u001b[39m z_log_var \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Combine losses\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\u001b[38;5;241m.\u001b[39mmean(reconstruction_loss \u001b[38;5;241m+\u001b[39m kl_loss)\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to convert 'x' to a tensor and failed. Error: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = pd.read_csv('../../data/BCP.csv')\n",
    "\n",
    "# Drop the Time column and scale the features\n",
    "features = data.drop(columns=['Time'])\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Define VAE parameters\n",
    "input_dim = features_scaled.shape[1]  # Number of features\n",
    "latent_dim = 2  # Dimension of the latent space\n",
    "\n",
    "# Encoder\n",
    "inputs = Input(shape=(input_dim,))\n",
    "h = Dense(16, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=1.0)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# Sampling layer\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "decoder_h = Dense(16, activation='relu')\n",
    "decoder_mean = Dense(input_dim)\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# Define VAE model\n",
    "vae = Model(inputs, x_decoded_mean)\n",
    "\n",
    "# Loss function\n",
    "def vae_loss(inputs, x_decoded_mean):\n",
    "    # Reconstruction loss\n",
    "    reconstruction_loss = MeanSquaredError()(inputs, x_decoded_mean)\n",
    "    reconstruction_loss *= input_dim  # Scale by input dimension to match overall scale\n",
    "\n",
    "    # KL divergence loss\n",
    "    kl_loss = 0.5 * K.sum(K.square(z_mean) + K.exp(z_log_var) - z_log_var - 1, axis=-1)\n",
    "    \n",
    "    # Combine losses\n",
    "    return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "# Compile the model\n",
    "vae.compile(optimizer=Adam(), loss=vae_loss)\n",
    "\n",
    "# Train the VAE model\n",
    "vae.fit(features_scaled, features_scaled,\n",
    "        epochs=50,  # Adjust epochs as needed\n",
    "        batch_size=32,\n",
    "        validation_split=0.2)\n",
    "\n",
    "# Calculate reconstruction loss for anomaly detection\n",
    "reconstructed = vae.predict(features_scaled)\n",
    "reconstruction_error = np.mean(np.square(features_scaled - reconstructed), axis=1)\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold = np.percentile(reconstruction_error, 95)  # Using the 95th percentile as threshold\n",
    "\n",
    "# Identify anomalies\n",
    "anomalies = reconstruction_error > threshold\n",
    "\n",
    "# Print results\n",
    "print(\"Threshold for anomaly detection:\", threshold)\n",
    "print(\"Number of anomalies detected:\", np.sum(anomalies))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
