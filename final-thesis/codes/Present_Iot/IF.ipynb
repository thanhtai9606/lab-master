{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ead8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/ai4i2020.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 1) Load & preprocess\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m     27\u001b[39m csv_path = \u001b[33m\"\u001b[39m\u001b[33m../../data/ai4i2020.csv\u001b[39m\u001b[33m\"\u001b[39m   \u001b[38;5;66;03m# đổi thành \"/mnt/data/ai4i2020.csv\" nếu cần\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTổng số dòng:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPhân phối nhãn Machine failure:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, df[\u001b[33m\"\u001b[39m\u001b[33mMachine failure\u001b[39m\u001b[33m\"\u001b[39m].value_counts())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    935\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    936\u001b[39m     dialect,\n\u001b[32m    937\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    945\u001b[39m )\n\u001b[32m    946\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    608\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1447\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1704\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1705\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1712\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1714\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1716\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    859\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    862\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m863\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    871\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    872\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../../data/ai4i2020.csv'"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Isolation Forest anomaly detection with manual threshold option\n",
    "# Dataset: ai4i2020.csv\n",
    "# - Train: ONLY normal\n",
    "# - VAL (balanced): chọn ngưỡng (manual / F1 / Precision≥target)\n",
    "# - TEST Balanced & Imbalanced dùng cùng ngưỡng\n",
    "# ==========================================\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    precision_recall_fscore_support, precision_recall_curve\n",
    ")\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# ------------------------------\n",
    "# 0) Reproducibility\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Load & preprocess\n",
    "# ------------------------------\n",
    "csv_path = \"../../../data/ai4i2020.csv\"   # đổi thành \"/mnt/data/ai4i2020.csv\" nếu cần\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Tổng số dòng:\", len(df))\n",
    "print(\"Phân phối nhãn Machine failure:\\n\", df[\"Machine failure\"].value_counts())\n",
    "print(\"Tỷ lệ (%):\\n\", df[\"Machine failure\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "drop_cols = ['UDI', 'Product ID', 'Type', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "X_df = df.drop(columns=drop_cols)\n",
    "y = df['Machine failure'].to_numpy().astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_all = scaler.fit_transform(X_df).astype(np.float32)\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Build splits (auto theo thực tế n_anom≈339)\n",
    "# ------------------------------\n",
    "normal_idx = np.where(y == 0)[0]\n",
    "anom_idx   = np.where(y == 1)[0]\n",
    "n_normal, n_anom = len(normal_idx), len(anom_idx)\n",
    "print(f\"\\nNormal: {n_normal} | Anomaly: {n_anom}\")\n",
    "\n",
    "# xáo trộn\n",
    "rng = np.random.default_rng(SEED)\n",
    "rng.shuffle(normal_idx); rng.shuffle(anom_idx)\n",
    "\n",
    "# Train normal\n",
    "TRAIN_NORMAL = min(8000, n_normal - 2000) if n_normal > 2000 else max(1000, n_normal // 2)\n",
    "train_norm_idx = normal_idx[:TRAIN_NORMAL]\n",
    "\n",
    "# Validation balanced\n",
    "VAL_ANOM = min(150, n_anom // 2)\n",
    "VAL_NORM = VAL_ANOM\n",
    "val_anom_idx = anom_idx[:VAL_ANOM]\n",
    "val_norm_idx = normal_idx[TRAIN_NORMAL : TRAIN_NORMAL + VAL_NORM]\n",
    "\n",
    "# Test balanced\n",
    "TEST_ANOM = min(200, n_anom - VAL_ANOM)\n",
    "TEST_NORM_BAL = TEST_ANOM\n",
    "test_bal_anom_idx = anom_idx[VAL_ANOM : VAL_ANOM + TEST_ANOM]\n",
    "test_bal_norm_idx = normal_idx[TRAIN_NORMAL + VAL_NORM :\n",
    "                               TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL]\n",
    "\n",
    "# Test imbalanced ~4:1\n",
    "TEST_IMB_NORM = min(800, n_normal - (TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL))\n",
    "test_imb_norm_idx = normal_idx[TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL :\n",
    "                               TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL + TEST_IMB_NORM]\n",
    "test_imb_anom_idx = test_bal_anom_idx  # dùng cùng anomaly để so công bằng\n",
    "\n",
    "def take(idx):\n",
    "    return X_all[idx], y[idx]\n",
    "\n",
    "X_train, y_train = take(train_norm_idx)           # toàn 0\n",
    "X_val   = np.vstack([X_all[val_norm_idx], X_all[val_anom_idx]])\n",
    "y_val   = np.hstack([np.zeros(len(val_norm_idx), dtype=int),\n",
    "                     np.ones (len(val_anom_idx), dtype=int)])\n",
    "\n",
    "X_test_bal = np.vstack([X_all[test_bal_norm_idx], X_all[test_bal_anom_idx]])\n",
    "y_test_bal = np.hstack([np.zeros(len(test_bal_norm_idx), dtype=int),\n",
    "                        np.ones (len(test_bal_anom_idx), dtype=int)])\n",
    "\n",
    "X_test_imb = np.vstack([X_all[test_imb_norm_idx], X_all[test_imb_anom_idx]])\n",
    "y_test_imb = np.hstack([np.zeros(len(test_imb_norm_idx), dtype=int),\n",
    "                        np.ones (len(test_imb_anom_idx), dtype=int)])\n",
    "\n",
    "print(\"\\n--- Split summary (auto) ---\")\n",
    "print(f\"Train normal size          : {X_train.shape[0]}\")\n",
    "print(f\"VAL balanced (norm/anom)   : {len(val_norm_idx)} / {len(val_anom_idx)}\")\n",
    "print(f\"TEST balanced (norm/anom)  : {len(test_bal_norm_idx)} / {len(test_bal_anom_idx)}\")\n",
    "print(f\"TEST imbalanced (norm/anom): {len(test_imb_norm_idx)} / {len(test_imb_anom_idx)}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Fit Isolation Forest (ONLY normal)\n",
    "# ------------------------------\n",
    "clf = IsolationForest(\n",
    "    n_estimators=400,\n",
    "    max_samples=512,\n",
    "    contamination=\"auto\",   # ta sẽ tự đặt ngưỡng nên không dựa vào predict()\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(X_train)  # chỉ normal\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Scoring (cao hơn => bất thường hơn)\n",
    "# ------------------------------\n",
    "def anomaly_score(model, X):\n",
    "    # score_samples: higher => more normal, nên đảo dấu\n",
    "    return -model.score_samples(X)\n",
    "\n",
    "val_scores  = anomaly_score(clf, X_val)\n",
    "# (test scores sẽ tính trong evaluate để in ROC AUC thống nhất)\n",
    "\n",
    "# ------------------------------\n",
    "# 5) Threshold selection (manual / f1 / p_at)\n",
    "# ------------------------------\n",
    "MODE = \"manual\"    # \"manual\" | \"f1\" | \"p_at\"\n",
    "THR_MANUAL = np.percentile(val_scores, 95)  # gợi ý: dùng percentile trên VAL (thay số tùy mục tiêu)\n",
    "TARGET_P   = 0.60  # dùng khi MODE=\"p_at\"\n",
    "\n",
    "def best_f1_threshold(y_true, scores, percentiles=np.linspace(50, 99.5, 200)):\n",
    "    thrs = np.percentile(scores, percentiles)\n",
    "    best_f1, best_thr = -1.0, None\n",
    "    for t in thrs:\n",
    "        y_pred = (scores >= t).astype(int)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, labels=[0,1], average=None, zero_division=0\n",
    "        )\n",
    "        if f1[1] > best_f1:\n",
    "            best_f1, best_thr = float(f1[1]), float(t)\n",
    "    return best_thr, best_f1\n",
    "\n",
    "def threshold_for_precision(y_true, scores, target_p=0.60):\n",
    "    p, r, thr = precision_recall_curve(y_true, scores)\n",
    "    # thr có độ dài len(p)-1\n",
    "    idx = np.where(p[:-1] >= target_p)[0]\n",
    "    if len(idx) == 0:\n",
    "        # fallback: 95th percentile nếu không đạt precision mục tiêu\n",
    "        return float(np.percentile(scores, 95)), float(p[1] if len(p)>1 else 0.0), float(r[1] if len(r)>1 else 0.0)\n",
    "    i = idx[0]\n",
    "    return float(thr[i]), float(p[i]), float(r[i])\n",
    "\n",
    "if MODE == \"manual\":\n",
    "    thr = float(THR_MANUAL)\n",
    "    pct = (val_scores <= thr).mean() * 100.0\n",
    "    print(f\"\\n[VAL] Manual threshold selected: thr={thr:.6f} (~percentile {pct:.2f}%)\")\n",
    "elif MODE == \"f1\":\n",
    "    thr, best_f1 = best_f1_threshold(y_val, val_scores)\n",
    "    print(f\"\\n[VAL balanced] Best F1(Class 1)={best_f1:.3f} at threshold={thr:.6f}\")\n",
    "else:  # MODE == \"p_at\"\n",
    "    thr, p_at, r_at = threshold_for_precision(y_val, val_scores, TARGET_P)\n",
    "    print(f\"\\n[VAL balanced] Threshold for Precision≥{TARGET_P:.2f}: thr={thr:.6f} (P={p_at:.3f}, R={r_at:.3f})\")\n",
    "\n",
    "# ------------------------------\n",
    "# 6) Evaluate\n",
    "# ------------------------------\n",
    "def evaluate(name: str, X_np: np.ndarray, y_true: np.ndarray, thr: float):\n",
    "    scores = anomaly_score(clf, X_np)\n",
    "    y_pred = (scores >= thr).astype(int)\n",
    "    print(f\"\\n===== {name} @thr={thr:.6f} =====\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "    print(\"ROC AUC (scores):\", roc_auc_score(y_true, scores))\n",
    "\n",
    "evaluate(\"TEST Balanced\",   X_test_bal, y_test_bal, thr)\n",
    "evaluate(\"TEST Imbalanced\", X_test_imb, y_test_imb, thr)\n",
    "\n",
    "# ------------------------------\n",
    "# 7) (Optional) Quick sweep ngưỡng để so sánh\n",
    "# ------------------------------\n",
    "candidates = [np.percentile(val_scores, p) for p in [80, 85, 90, 95, 97.5, 99]]\n",
    "print(\"\\n>>> Quick sweep on percentile-based thresholds (from VAL):\")\n",
    "for t in candidates:\n",
    "    print(f\"\\n-- Try thr={t:.6f} on TEST Balanced --\")\n",
    "    evaluate(\"TEST Balanced\", X_test_bal, y_test_bal, t)\n",
    "    print(f\"\\n-- Try thr={t:.6f} on TEST Imbalanced --\")\n",
    "    evaluate(\"TEST Imbalanced\", X_test_imb, y_test_imb, t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
