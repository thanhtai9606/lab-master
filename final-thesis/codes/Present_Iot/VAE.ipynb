{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f091680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Tổng số dòng: 10000\n",
      "Phân phối nhãn Machine failure:\n",
      " Machine failure\n",
      "0    9661\n",
      "1     339\n",
      "Name: count, dtype: int64\n",
      "Tỷ lệ (%):\n",
      " Machine failure\n",
      "0    96.61\n",
      "1     3.39\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Normal: 9661 | Anomaly: 339\n",
      "\n",
      "--- Split summary (auto) ---\n",
      "Train normal size          : 7661\n",
      "VAL balanced (norm/anom)   : 150 / 150\n",
      "TEST balanced (norm/anom)  : 189 / 189\n",
      "TEST imbalanced (norm/anom): 800 / 189\n",
      "[VAE] Epoch   1/40 | loss=0.813664 | recon=0.702319 | kl=0.111345\n",
      "[VAE] Epoch   5/40 | loss=0.515744 | recon=0.229941 | kl=0.285803\n",
      "[VAE] Epoch  10/40 | loss=0.513013 | recon=0.226496 | kl=0.286517\n",
      "[VAE] Epoch  15/40 | loss=0.511682 | recon=0.223840 | kl=0.287842\n",
      "[VAE] Epoch  20/40 | loss=0.510439 | recon=0.223741 | kl=0.286698\n",
      "[VAE] Epoch  25/40 | loss=0.512371 | recon=0.224506 | kl=0.287865\n",
      "[VAE] Epoch  30/40 | loss=0.508690 | recon=0.223101 | kl=0.285590\n",
      "[VAE] Epoch  35/40 | loss=0.507612 | recon=0.223040 | kl=0.284572\n",
      "[VAE] Epoch  40/40 | loss=0.507629 | recon=0.224387 | kl=0.283242\n",
      "\n",
      "[VAL] Manual threshold selected: thr=0.600000 (~percentile 92.00%)\n",
      "\n",
      "===== TEST Balanced @thr=0.600000 =====\n",
      "Confusion Matrix:\n",
      " [[183   6]\n",
      " [162  27]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5304    0.9683    0.6854       189\n",
      "           1     0.8182    0.1429    0.2432       189\n",
      "\n",
      "    accuracy                         0.5556       378\n",
      "   macro avg     0.6743    0.5556    0.4643       378\n",
      "weighted avg     0.6743    0.5556    0.4643       378\n",
      "\n",
      "ROC AUC (scores): 0.7301867248957197\n",
      "\n",
      "===== TEST Imbalanced @thr=0.600000 =====\n",
      "Confusion Matrix:\n",
      " [[765  35]\n",
      " [167  22]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8208    0.9563    0.8834       800\n",
      "           1     0.3860    0.1164    0.1789       189\n",
      "\n",
      "    accuracy                         0.7958       989\n",
      "   macro avg     0.6034    0.5363    0.5311       989\n",
      "weighted avg     0.7377    0.7958    0.7487       989\n",
      "\n",
      "ROC AUC (scores): 0.6931547619047619\n",
      "\n",
      ">>> Quick sweep on percentile-based thresholds (from VAL):\n",
      "\n",
      "-- Try thr=0.258836 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.258836 =====\n",
      "Confusion Matrix:\n",
      " [[133  56]\n",
      " [ 70 119]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6552    0.7037    0.6786       189\n",
      "           1     0.6800    0.6296    0.6538       189\n",
      "\n",
      "    accuracy                         0.6667       378\n",
      "   macro avg     0.6676    0.6667    0.6662       378\n",
      "weighted avg     0.6676    0.6667    0.6662       378\n",
      "\n",
      "ROC AUC (scores): 0.6972089247221522\n",
      "\n",
      "-- Try thr=0.258836 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.258836 =====\n",
      "Confusion Matrix:\n",
      " [[534 266]\n",
      " [ 69 120]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8856    0.6675    0.7612       800\n",
      "           1     0.3109    0.6349    0.4174       189\n",
      "\n",
      "    accuracy                         0.6613       989\n",
      "   macro avg     0.5982    0.6512    0.5893       989\n",
      "weighted avg     0.7757    0.6613    0.6955       989\n",
      "\n",
      "ROC AUC (scores): 0.7167063492063491\n",
      "\n",
      "-- Try thr=0.309371 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.309371 =====\n",
      "Confusion Matrix:\n",
      " [[136  53]\n",
      " [ 89 100]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6044    0.7196    0.6570       189\n",
      "           1     0.6536    0.5291    0.5848       189\n",
      "\n",
      "    accuracy                         0.6243       378\n",
      "   macro avg     0.6290    0.6243    0.6209       378\n",
      "weighted avg     0.6290    0.6243    0.6209       378\n",
      "\n",
      "ROC AUC (scores): 0.7158254248201338\n",
      "\n",
      "-- Try thr=0.309371 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.309371 =====\n",
      "Confusion Matrix:\n",
      " [[625 175]\n",
      " [ 80 109]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8865    0.7812    0.8306       800\n",
      "           1     0.3838    0.5767    0.4609       189\n",
      "\n",
      "    accuracy                         0.7422       989\n",
      "   macro avg     0.6352    0.6790    0.6457       989\n",
      "weighted avg     0.7905    0.7422    0.7599       989\n",
      "\n",
      "ROC AUC (scores): 0.7538756613756613\n",
      "\n",
      "-- Try thr=0.357783 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.357783 =====\n",
      "Confusion Matrix:\n",
      " [[154  35]\n",
      " [114  75]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5746    0.8148    0.6740       189\n",
      "           1     0.6818    0.3968    0.5017       189\n",
      "\n",
      "    accuracy                         0.6058       378\n",
      "   macro avg     0.6282    0.6058    0.5878       378\n",
      "weighted avg     0.6282    0.6058    0.5878       378\n",
      "\n",
      "ROC AUC (scores): 0.7105904090031074\n",
      "\n",
      "-- Try thr=0.357783 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.357783 =====\n",
      "Confusion Matrix:\n",
      " [[646 154]\n",
      " [101  88]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8648    0.8075    0.8352       800\n",
      "           1     0.3636    0.4656    0.4084       189\n",
      "\n",
      "    accuracy                         0.7422       989\n",
      "   macro avg     0.6142    0.6366    0.6218       989\n",
      "weighted avg     0.7690    0.7422    0.7536       989\n",
      "\n",
      "ROC AUC (scores): 0.6833862433862433\n",
      "\n",
      "-- Try thr=0.437079 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.437079 =====\n",
      "Confusion Matrix:\n",
      " [[165  24]\n",
      " [136  53]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5482    0.8730    0.6735       189\n",
      "           1     0.6883    0.2804    0.3985       189\n",
      "\n",
      "    accuracy                         0.5767       378\n",
      "   macro avg     0.6182    0.5767    0.5360       378\n",
      "weighted avg     0.6182    0.5767    0.5360       378\n",
      "\n",
      "ROC AUC (scores): 0.6739173035469332\n",
      "\n",
      "-- Try thr=0.437079 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.437079 =====\n",
      "Confusion Matrix:\n",
      " [[720  80]\n",
      " [137  52]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8401    0.9000    0.8690       800\n",
      "           1     0.3939    0.2751    0.3240       189\n",
      "\n",
      "    accuracy                         0.7806       989\n",
      "   macro avg     0.6170    0.5876    0.5965       989\n",
      "weighted avg     0.7549    0.7806    0.7649       989\n",
      "\n",
      "ROC AUC (scores): 0.7066666666666666\n",
      "\n",
      "-- Try thr=0.485070 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.485070 =====\n",
      "Confusion Matrix:\n",
      " [[179  10]\n",
      " [155  34]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5359    0.9471    0.6845       189\n",
      "           1     0.7727    0.1799    0.2918       189\n",
      "\n",
      "    accuracy                         0.5635       378\n",
      "   macro avg     0.6543    0.5635    0.4882       378\n",
      "weighted avg     0.6543    0.5635    0.4882       378\n",
      "\n",
      "ROC AUC (scores): 0.6781165140953501\n",
      "\n",
      "-- Try thr=0.485070 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.485070 =====\n",
      "Confusion Matrix:\n",
      " [[726  74]\n",
      " [135  54]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8432    0.9075    0.8742       800\n",
      "           1     0.4219    0.2857    0.3407       189\n",
      "\n",
      "    accuracy                         0.7887       989\n",
      "   macro avg     0.6325    0.5966    0.6074       989\n",
      "weighted avg     0.7627    0.7887    0.7722       989\n",
      "\n",
      "ROC AUC (scores): 0.6908465608465608\n",
      "\n",
      "-- Try thr=0.555005 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.555005 =====\n",
      "Confusion Matrix:\n",
      " [[181   8]\n",
      " [163  26]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5262    0.9577    0.6792       189\n",
      "           1     0.7647    0.1376    0.2332       189\n",
      "\n",
      "    accuracy                         0.5476       378\n",
      "   macro avg     0.6454    0.5476    0.4562       378\n",
      "weighted avg     0.6454    0.5476    0.4562       378\n",
      "\n",
      "ROC AUC (scores): 0.6820077825368831\n",
      "\n",
      "-- Try thr=0.555005 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.555005 =====\n",
      "Confusion Matrix:\n",
      " [[756  44]\n",
      " [160  29]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8253    0.9450    0.8811       800\n",
      "           1     0.3973    0.1534    0.2214       189\n",
      "\n",
      "    accuracy                         0.7937       989\n",
      "   macro avg     0.6113    0.5492    0.5512       989\n",
      "weighted avg     0.7435    0.7937    0.7550       989\n",
      "\n",
      "ROC AUC (scores): 0.6717857142857142\n",
      "\n",
      "-- Try thr=0.700216 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.700216 =====\n",
      "Confusion Matrix:\n",
      " [[184   5]\n",
      " [178  11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5083    0.9735    0.6679       189\n",
      "           1     0.6875    0.0582    0.1073       189\n",
      "\n",
      "    accuracy                         0.5159       378\n",
      "   macro avg     0.5979    0.5159    0.3876       378\n",
      "weighted avg     0.5979    0.5159    0.3876       378\n",
      "\n",
      "ROC AUC (scores): 0.7011001931636852\n",
      "\n",
      "-- Try thr=0.700216 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.700216 =====\n",
      "Confusion Matrix:\n",
      " [[784  16]\n",
      " [175  14]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8175    0.9800    0.8914       800\n",
      "           1     0.4667    0.0741    0.1279       189\n",
      "\n",
      "    accuracy                         0.8069       989\n",
      "   macro avg     0.6421    0.5270    0.5096       989\n",
      "weighted avg     0.7505    0.8069    0.7455       989\n",
      "\n",
      "ROC AUC (scores): 0.7104761904761905\n",
      "\n",
      "-- Try thr=0.801539 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.801539 =====\n",
      "Confusion Matrix:\n",
      " [[186   3]\n",
      " [175  14]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5152    0.9841    0.6764       189\n",
      "           1     0.8235    0.0741    0.1359       189\n",
      "\n",
      "    accuracy                         0.5291       378\n",
      "   macro avg     0.6694    0.5291    0.4061       378\n",
      "weighted avg     0.6694    0.5291    0.4061       378\n",
      "\n",
      "ROC AUC (scores): 0.7186248985190784\n",
      "\n",
      "-- Try thr=0.801539 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.801539 =====\n",
      "Confusion Matrix:\n",
      " [[794   6]\n",
      " [179  10]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8160    0.9925    0.8957       800\n",
      "           1     0.6250    0.0529    0.0976       189\n",
      "\n",
      "    accuracy                         0.8129       989\n",
      "   macro avg     0.7205    0.5227    0.4966       989\n",
      "weighted avg     0.7795    0.8129    0.7431       989\n",
      "\n",
      "ROC AUC (scores): 0.7104960317460317\n",
      "\n",
      "-- Try thr=0.952365 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.952365 =====\n",
      "Confusion Matrix:\n",
      " [[189   0]\n",
      " [186   3]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5040    1.0000    0.6702       189\n",
      "           1     1.0000    0.0159    0.0312       189\n",
      "\n",
      "    accuracy                         0.5079       378\n",
      "   macro avg     0.7520    0.5079    0.3507       378\n",
      "weighted avg     0.7520    0.5079    0.3507       378\n",
      "\n",
      "ROC AUC (scores): 0.685955040452395\n",
      "\n",
      "-- Try thr=0.952365 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.952365 =====\n",
      "Confusion Matrix:\n",
      " [[796   4]\n",
      " [184   5]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8122    0.9950    0.8944       800\n",
      "           1     0.5556    0.0265    0.0505       189\n",
      "\n",
      "    accuracy                         0.8099       989\n",
      "   macro avg     0.6839    0.5107    0.4724       989\n",
      "weighted avg     0.7632    0.8099    0.7331       989\n",
      "\n",
      "ROC AUC (scores): 0.6988955026455027\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# VAE anomaly detection (PyTorch) with manual threshold option\n",
    "# Dataset: ai4i2020.csv\n",
    "# - Train: ONLY normal\n",
    "# - VAL (balanced): dùng để chọn ngưỡng (manual / F1 / Precision≥target)\n",
    "# - TEST Balanced & Imbalanced dùng cùng ngưỡng\n",
    "# ==========================================\n",
    "\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    precision_recall_fscore_support, precision_recall_curve\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ------------------------------\n",
    "# 0) Reproducibility & determinism\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Load & preprocess\n",
    "# ------------------------------\n",
    "csv_path = \"../../data/ai4i2020.csv\"   # đổi thành \"/mnt/data/ai4i2020.csv\" nếu cần\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Tổng số dòng:\", len(df))\n",
    "print(\"Phân phối nhãn Machine failure:\\n\", df[\"Machine failure\"].value_counts())\n",
    "print(\"Tỷ lệ (%):\\n\", df[\"Machine failure\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "drop_cols = ['UDI', 'Product ID', 'Type', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "X_df = df.drop(columns=drop_cols)\n",
    "y = df['Machine failure'].to_numpy().astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_all = scaler.fit_transform(X_df).astype(np.float32)\n",
    "input_dim = X_all.shape[1]\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Build splits (auto theo thực tế n_anom≈339)\n",
    "# ------------------------------\n",
    "normal_idx = np.where(y == 0)[0]\n",
    "anom_idx   = np.where(y == 1)[0]\n",
    "n_normal, n_anom = len(normal_idx), len(anom_idx)\n",
    "print(f\"\\nNormal: {n_normal} | Anomaly: {n_anom}\")\n",
    "\n",
    "# xáo trộn để không phụ thuộc thứ tự\n",
    "rng = np.random.default_rng(SEED)\n",
    "rng.shuffle(normal_idx); rng.shuffle(anom_idx)\n",
    "\n",
    "# Train normal\n",
    "TRAIN_NORMAL = min(8000, n_normal - 2000) if n_normal > 2000 else max(1000, n_normal // 2)\n",
    "train_norm_idx = normal_idx[:TRAIN_NORMAL]\n",
    "\n",
    "# Validation balanced\n",
    "VAL_ANOM = min(150, n_anom // 2)\n",
    "VAL_NORM = VAL_ANOM\n",
    "val_anom_idx = anom_idx[:VAL_ANOM]\n",
    "val_norm_idx = normal_idx[TRAIN_NORMAL : TRAIN_NORMAL + VAL_NORM]\n",
    "\n",
    "# Test balanced\n",
    "TEST_ANOM = min(200, n_anom - VAL_ANOM)\n",
    "TEST_NORM_BAL = TEST_ANOM\n",
    "test_bal_anom_idx = anom_idx[VAL_ANOM : VAL_ANOM + TEST_ANOM]\n",
    "test_bal_norm_idx = normal_idx[TRAIN_NORMAL + VAL_NORM :\n",
    "                               TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL]\n",
    "\n",
    "# Test imbalanced ~4:1\n",
    "TEST_IMB_NORM = min(800, n_normal - (TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL))\n",
    "test_imb_norm_idx = normal_idx[TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL :\n",
    "                               TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL + TEST_IMB_NORM]\n",
    "test_imb_anom_idx = test_bal_anom_idx  # dùng cùng anomaly để so công bằng\n",
    "\n",
    "def take(idx):\n",
    "    return X_all[idx], y[idx]\n",
    "\n",
    "X_train, y_train = take(train_norm_idx)           # toàn 0 (normal only)\n",
    "X_val   = np.vstack([X_all[val_norm_idx], X_all[val_anom_idx]])\n",
    "y_val   = np.hstack([np.zeros(len(val_norm_idx), dtype=int),\n",
    "                     np.ones (len(val_anom_idx), dtype=int)])\n",
    "\n",
    "X_test_bal = np.vstack([X_all[test_bal_norm_idx], X_all[test_bal_anom_idx]])\n",
    "y_test_bal = np.hstack([np.zeros(len(test_bal_norm_idx), dtype=int),\n",
    "                        np.ones (len(test_bal_anom_idx), dtype=int)])\n",
    "\n",
    "X_test_imb = np.vstack([X_all[test_imb_norm_idx], X_all[test_imb_anom_idx]])\n",
    "y_test_imb = np.hstack([np.zeros(len(test_imb_norm_idx), dtype=int),\n",
    "                        np.ones (len(test_imb_anom_idx), dtype=int)])\n",
    "\n",
    "print(\"\\n--- Split summary (auto) ---\")\n",
    "print(f\"Train normal size          : {X_train.shape[0]}\")\n",
    "print(f\"VAL balanced (norm/anom)   : {len(val_norm_idx)} / {len(val_anom_idx)}\")\n",
    "print(f\"TEST balanced (norm/anom)  : {len(test_bal_norm_idx)} / {len(test_bal_anom_idx)}\")\n",
    "print(f\"TEST imbalanced (norm/anom): {len(test_imb_norm_idx)} / {len(test_imb_anom_idx)}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Define VAE\n",
    "# ------------------------------\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=8, hidden=128):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden), nn.ReLU(),\n",
    "        )\n",
    "        self.enc_mu     = nn.Linear(hidden, latent_dim)\n",
    "        self.enc_logvar = nn.Linear(hidden, latent_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, input_dim)  # tái tạo z-score\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar); eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, lv = self.enc_mu(h), self.enc_logvar(h)\n",
    "        z = self.reparameterize(mu, lv)\n",
    "        xhat = self.decoder(z)\n",
    "        return xhat, mu, lv, z\n",
    "\n",
    "def vae_loss_fn(x, xhat, mu, logvar, recon=\"mse\", beta=1.0):\n",
    "    if recon == \"mse\":\n",
    "        recon_loss = nn.functional.mse_loss(xhat, x, reduction=\"mean\")\n",
    "    else:\n",
    "        recon_loss = nn.functional.l1_loss(xhat, x, reduction=\"mean\")\n",
    "    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + beta * kl, recon_loss, kl\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Train VAE (ONLY normal)\n",
    "# ------------------------------\n",
    "vae = VAE(input_dim=input_dim, latent_dim=8, hidden=128).to(device)\n",
    "opt = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "batch_size = 128\n",
    "epochs     = 40   # có thể tăng nếu có GPU\n",
    "train_loader = DataLoader(TensorDataset(torch.from_numpy(X_train)),\n",
    "                          batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    vae.train()\n",
    "    total = recon_total = kl_total = 0.0\n",
    "    steps = 0\n",
    "    for (xb,) in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        opt.zero_grad()\n",
    "        xhat, mu, lv, z = vae(xb)\n",
    "        loss, rl, kl = vae_loss_fn(xb, xhat, mu, lv, recon=\"mse\", beta=1.0)\n",
    "        loss.backward(); opt.step()\n",
    "        total += loss.item(); recon_total += rl.item(); kl_total += kl.item(); steps += 1\n",
    "    if ep == 1 or ep % 5 == 0:\n",
    "        print(f\"[VAE] Epoch {ep:3d}/{epochs} | loss={total/steps:.6f} | recon={recon_total/steps:.6f} | kl={kl_total/steps:.6f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 5) Scoring: reconstruction error (MSE)\n",
    "# ------------------------------\n",
    "@torch.no_grad()\n",
    "def recon_error(x_np: np.ndarray, model: VAE, agg=\"mse\"):\n",
    "    model.eval()\n",
    "    xt = torch.from_numpy(x_np).to(device)\n",
    "    xhat, _, _, _ = model(xt)\n",
    "    if agg == \"mse\":\n",
    "        err = torch.mean((xhat - xt)**2, dim=1)\n",
    "    else:\n",
    "        err = torch.mean(torch.abs(xhat - xt), dim=1)\n",
    "    return err.detach().cpu().numpy()\n",
    "\n",
    "val_scores  = recon_error(X_val, vae, agg=\"mse\")\n",
    "\n",
    "# ------------------------------\n",
    "# 6) Threshold selection (manual / f1 / p_at)\n",
    "# ------------------------------\n",
    "MODE = \"manual\"    # \"manual\" | \"f1\" | \"p_at\"\n",
    "THR_MANUAL = 0.60  # <-- tự đặt ngưỡng theo kinh nghiệm/target (thử 0.4~0.8)\n",
    "TARGET_P   = 0.60  # dùng khi MODE=\"p_at\"\n",
    "\n",
    "def best_f1_threshold(y_true, scores, percentiles=np.linspace(50, 99.5, 200)):\n",
    "    thrs = np.percentile(scores, percentiles)\n",
    "    best_f1, best_thr = -1.0, None\n",
    "    for t in thrs:\n",
    "        y_pred = (scores >= t).astype(int)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, labels=[0,1], average=None, zero_division=0\n",
    "        )\n",
    "        if f1[1] > best_f1:\n",
    "            best_f1, best_thr = float(f1[1]), float(t)\n",
    "    return best_thr, best_f1\n",
    "\n",
    "def threshold_for_precision(y_true, scores, target_p=0.60):\n",
    "    p, r, thr = precision_recall_curve(y_true, scores)\n",
    "    idx = np.where(p[:-1] >= target_p)[0]\n",
    "    if len(idx) == 0:\n",
    "        # fallback: 95th percentile nếu không đạt precision mục tiêu\n",
    "        return float(np.percentile(scores, 95)), float(p[1] if len(p)>1 else 0.0), float(r[1] if len(r)>1 else 0.0)\n",
    "    i = idx[0]\n",
    "    return float(thr[i]), float(p[i]), float(r[i])\n",
    "\n",
    "if MODE == \"manual\":\n",
    "    thr = float(THR_MANUAL)\n",
    "    pct = (val_scores <= thr).mean() * 100.0\n",
    "    print(f\"\\n[VAL] Manual threshold selected: thr={thr:.6f} (~percentile {pct:.2f}%)\")\n",
    "elif MODE == \"f1\":\n",
    "    thr, best_f1 = best_f1_threshold(y_val, val_scores)\n",
    "    print(f\"\\n[VAL balanced] Best F1(Class 1)={best_f1:.3f} at threshold={thr:.6f}\")\n",
    "else:  # MODE == \"p_at\"\n",
    "    thr, p_at, r_at = threshold_for_precision(y_val, val_scores, TARGET_P)\n",
    "    print(f\"\\n[VAL balanced] Threshold for Precision≥{TARGET_P:.2f}: thr={thr:.6f} (P={p_at:.3f}, R={r_at:.3f})\")\n",
    "\n",
    "# ------------------------------\n",
    "# 7) Evaluate on TEST sets\n",
    "# ------------------------------\n",
    "def evaluate(name: str, X_np: np.ndarray, y_true: np.ndarray, thr: float):\n",
    "    scores = recon_error(X_np, vae, agg=\"mse\")\n",
    "    y_pred = (scores >= thr).astype(int)\n",
    "    print(f\"\\n===== {name} @thr={thr:.6f} =====\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "    print(\"ROC AUC (scores):\", roc_auc_score(y_true, scores))\n",
    "\n",
    "evaluate(\"TEST Balanced\",   X_test_bal, y_test_bal, thr)\n",
    "evaluate(\"TEST Imbalanced\", X_test_imb, y_test_imb, thr)\n",
    "\n",
    "# ------------------------------\n",
    "# 8) (Optional) Quick sweep ngưỡng để so sánh\n",
    "# ------------------------------\n",
    "candidates = [np.percentile(val_scores, p) for p in [50, 60, 70, 80, 85, 90, 95, 97.5, 99]]\n",
    "print(\"\\n>>> Quick sweep on percentile-based thresholds (from VAL):\")\n",
    "for t in candidates:\n",
    "    print(f\"\\n-- Try thr={t:.6f} on TEST Balanced --\")\n",
    "    evaluate(\"TEST Balanced\", X_test_bal, y_test_bal, t)\n",
    "    print(f\"\\n-- Try thr={t:.6f} on TEST Imbalanced --\")\n",
    "    evaluate(\"TEST Imbalanced\", X_test_imb, y_test_imb, t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
