{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15879dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Tổng số dòng: 10000\n",
      "Phân phối nhãn Machine failure:\n",
      " Machine failure\n",
      "0    9661\n",
      "1     339\n",
      "Name: count, dtype: int64\n",
      "Tỷ lệ (%):\n",
      " Machine failure\n",
      "0    96.61\n",
      "1     3.39\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Normal: 9661 | Anomaly: 339\n",
      "\n",
      "--- Split summary (auto) ---\n",
      "Train normal size          : 7661\n",
      "VAL balanced (norm/anom)   : 150 / 150\n",
      "TEST balanced (norm/anom)  : 189 / 189\n",
      "TEST imbalanced (norm/anom): 800 / 189\n",
      "Epoch   1/60 | D: 1.1880 | G: 0.8020\n",
      "Epoch   5/60 | D: 1.2147 | G: 1.1743\n",
      "Epoch  10/60 | D: 1.3434 | G: 0.9222\n",
      "Epoch  15/60 | D: 1.3719 | G: 0.8032\n",
      "Epoch  20/60 | D: 1.3662 | G: 0.8109\n",
      "Epoch  25/60 | D: 1.3713 | G: 0.8206\n",
      "Epoch  30/60 | D: 1.3679 | G: 0.8151\n",
      "Epoch  35/60 | D: 1.3703 | G: 0.8069\n",
      "Epoch  40/60 | D: 1.3696 | G: 0.8155\n",
      "Epoch  45/60 | D: 1.3733 | G: 0.8118\n",
      "Epoch  50/60 | D: 1.3718 | G: 0.8104\n",
      "Epoch  55/60 | D: 1.3724 | G: 0.8075\n",
      "Epoch  60/60 | D: 1.3765 | G: 0.8117\n",
      "\n",
      "[VAL] Manual threshold selected: thr=0.600000 (~percentile 91.67%)\n",
      "\n",
      "===== TEST Balanced @thr=0.600000 =====\n",
      "Confusion Matrix:\n",
      " [[171  18]\n",
      " [165  24]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5089    0.9048    0.6514       189\n",
      "           1     0.5714    0.1270    0.2078       189\n",
      "\n",
      "    accuracy                         0.5159       378\n",
      "   macro avg     0.5402    0.5159    0.4296       378\n",
      "weighted avg     0.5402    0.5159    0.4296       378\n",
      "\n",
      "ROC AUC (scores): 0.32650261750790854\n",
      "\n",
      "===== TEST Imbalanced @thr=0.600000 =====\n",
      "Confusion Matrix:\n",
      " [[723  77]\n",
      " [165  24]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8142    0.9038    0.8566       800\n",
      "           1     0.2376    0.1270    0.1655       189\n",
      "\n",
      "    accuracy                         0.7553       989\n",
      "   macro avg     0.5259    0.5154    0.5111       989\n",
      "weighted avg     0.7040    0.7553    0.7246       989\n",
      "\n",
      "ROC AUC (scores): 0.3458002645502645\n",
      "\n",
      ">>> Quick sweep on a few manual thresholds:\n",
      "\n",
      "-- Try thr=0.300 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.300000 =====\n",
      "Confusion Matrix:\n",
      " [[  0 189]\n",
      " [  0 189]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       189\n",
      "           1     0.5000    1.0000    0.6667       189\n",
      "\n",
      "    accuracy                         0.5000       378\n",
      "   macro avg     0.2500    0.5000    0.3333       378\n",
      "weighted avg     0.2500    0.5000    0.3333       378\n",
      "\n",
      "ROC AUC (scores): 0.32650261750790854\n",
      "\n",
      "-- Try thr=0.300 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.300000 =====\n",
      "Confusion Matrix:\n",
      " [[  0 800]\n",
      " [  0 189]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       800\n",
      "           1     0.1911    1.0000    0.3209       189\n",
      "\n",
      "    accuracy                         0.1911       989\n",
      "   macro avg     0.0956    0.5000    0.1604       989\n",
      "weighted avg     0.0365    0.1911    0.0613       989\n",
      "\n",
      "ROC AUC (scores): 0.3458002645502645\n",
      "\n",
      "-- Try thr=0.400 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.400000 =====\n",
      "Confusion Matrix:\n",
      " [[  0 189]\n",
      " [  0 189]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       189\n",
      "           1     0.5000    1.0000    0.6667       189\n",
      "\n",
      "    accuracy                         0.5000       378\n",
      "   macro avg     0.2500    0.5000    0.3333       378\n",
      "weighted avg     0.2500    0.5000    0.3333       378\n",
      "\n",
      "ROC AUC (scores): 0.32650261750790854\n",
      "\n",
      "-- Try thr=0.400 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.400000 =====\n",
      "Confusion Matrix:\n",
      " [[  0 800]\n",
      " [  0 189]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       800\n",
      "           1     0.1911    1.0000    0.3209       189\n",
      "\n",
      "    accuracy                         0.1911       989\n",
      "   macro avg     0.0956    0.5000    0.1604       989\n",
      "weighted avg     0.0365    0.1911    0.0613       989\n",
      "\n",
      "ROC AUC (scores): 0.3458002645502645\n",
      "\n",
      "-- Try thr=0.500 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.500000 =====\n",
      "Confusion Matrix:\n",
      " [[ 13 176]\n",
      " [ 45 144]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2241    0.0688    0.1053       189\n",
      "           1     0.4500    0.7619    0.5658       189\n",
      "\n",
      "    accuracy                         0.4153       378\n",
      "   macro avg     0.3371    0.4153    0.3355       378\n",
      "weighted avg     0.3371    0.4153    0.3355       378\n",
      "\n",
      "ROC AUC (scores): 0.32650261750790854\n",
      "\n",
      "-- Try thr=0.500 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.500000 =====\n",
      "Confusion Matrix:\n",
      " [[ 75 725]\n",
      " [ 45 144]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6250    0.0938    0.1630       800\n",
      "           1     0.1657    0.7619    0.2722       189\n",
      "\n",
      "    accuracy                         0.2214       989\n",
      "   macro avg     0.3954    0.4278    0.2176       989\n",
      "weighted avg     0.5372    0.2214    0.1839       989\n",
      "\n",
      "ROC AUC (scores): 0.3458002645502645\n",
      "\n",
      "-- Try thr=0.600 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.600000 =====\n",
      "Confusion Matrix:\n",
      " [[171  18]\n",
      " [165  24]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5089    0.9048    0.6514       189\n",
      "           1     0.5714    0.1270    0.2078       189\n",
      "\n",
      "    accuracy                         0.5159       378\n",
      "   macro avg     0.5402    0.5159    0.4296       378\n",
      "weighted avg     0.5402    0.5159    0.4296       378\n",
      "\n",
      "ROC AUC (scores): 0.32650261750790854\n",
      "\n",
      "-- Try thr=0.600 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.600000 =====\n",
      "Confusion Matrix:\n",
      " [[723  77]\n",
      " [165  24]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8142    0.9038    0.8566       800\n",
      "           1     0.2376    0.1270    0.1655       189\n",
      "\n",
      "    accuracy                         0.7553       989\n",
      "   macro avg     0.5259    0.5154    0.5111       989\n",
      "weighted avg     0.7040    0.7553    0.7246       989\n",
      "\n",
      "ROC AUC (scores): 0.3458002645502645\n",
      "\n",
      "-- Try thr=0.700 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced @thr=0.700000 =====\n",
      "Confusion Matrix:\n",
      " [[189   0]\n",
      " [181   8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5108    1.0000    0.6762       189\n",
      "           1     1.0000    0.0423    0.0812       189\n",
      "\n",
      "    accuracy                         0.5212       378\n",
      "   macro avg     0.7554    0.5212    0.3787       378\n",
      "weighted avg     0.7554    0.5212    0.3787       378\n",
      "\n",
      "ROC AUC (scores): 0.32650261750790854\n",
      "\n",
      "-- Try thr=0.700 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced @thr=0.700000 =====\n",
      "Confusion Matrix:\n",
      " [[795   5]\n",
      " [181   8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8145    0.9938    0.8953       800\n",
      "           1     0.6154    0.0423    0.0792       189\n",
      "\n",
      "    accuracy                         0.8119       989\n",
      "   macro avg     0.7150    0.5180    0.4872       989\n",
      "weighted avg     0.7765    0.8119    0.7393       989\n",
      "\n",
      "ROC AUC (scores): 0.3458002645502645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/ltdung3979/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# GAN anomaly detection (PyTorch) with manual threshold option\n",
    "# Dataset: ai4i2020.csv\n",
    "# - Train: ONLY normal\n",
    "# - VAL (balanced): dùng để đánh giá/so sánh; có thể chọn ngưỡng thủ công (manual)\n",
    "# - TEST Balanced & Imbalanced dùng cùng ngưỡng\n",
    "# Stabilization: BCEWithLogitsLoss, label smoothing, input noise, Adam betas (0.5,0.999)\n",
    "# ==========================================\n",
    "\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    precision_recall_fscore_support, precision_recall_curve\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ------------------------------\n",
    "# 0) Reproducibility & determinism\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Load & preprocess\n",
    "# ------------------------------\n",
    "csv_path = \"../../data/ai4i2020.csv\"   # đổi thành \"/mnt/data/ai4i2020.csv\" nếu cần\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Tổng số dòng:\", len(df))\n",
    "print(\"Phân phối nhãn Machine failure:\\n\", df[\"Machine failure\"].value_counts())\n",
    "print(\"Tỷ lệ (%):\\n\", df[\"Machine failure\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Bỏ cột không dùng\n",
    "drop_cols = ['UDI', 'Product ID', 'Type', 'Machine failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n",
    "X_df = df.drop(columns=drop_cols)\n",
    "y = df['Machine failure'].to_numpy().astype(int)\n",
    "\n",
    "# Chuẩn hoá z-score\n",
    "scaler = StandardScaler()\n",
    "X_all = scaler.fit_transform(X_df).astype(np.float32)\n",
    "input_dim = X_all.shape[1]\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Build splits (auto theo thực tế n_anom=~339)\n",
    "# ------------------------------\n",
    "normal_idx = np.where(y == 0)[0]\n",
    "anom_idx   = np.where(y == 1)[0]\n",
    "n_normal, n_anom = len(normal_idx), len(anom_idx)\n",
    "print(f\"\\nNormal: {n_normal} | Anomaly: {n_anom}\")\n",
    "\n",
    "# xáo trộn\n",
    "rng = np.random.default_rng(SEED)\n",
    "rng.shuffle(normal_idx)\n",
    "rng.shuffle(anom_idx)\n",
    "\n",
    "# Train normal\n",
    "TRAIN_NORMAL = min(8000, n_normal - 2000) if n_normal > 2000 else max(1000, n_normal // 2)\n",
    "train_norm_idx = normal_idx[:TRAIN_NORMAL]\n",
    "\n",
    "# Validation balanced (norm = anom)\n",
    "VAL_ANOM = min(150, n_anom // 2)   # lấy 150 anom nếu đủ\n",
    "VAL_NORM = VAL_ANOM\n",
    "val_anom_idx = anom_idx[:VAL_ANOM]\n",
    "val_norm_idx = normal_idx[TRAIN_NORMAL : TRAIN_NORMAL + VAL_NORM]\n",
    "\n",
    "# Test balanced (ưu tiên 200 anom nếu đủ)\n",
    "TEST_ANOM = min(200, n_anom - VAL_ANOM)\n",
    "TEST_NORM_BAL = TEST_ANOM\n",
    "test_bal_anom_idx = anom_idx[VAL_ANOM : VAL_ANOM + TEST_ANOM]\n",
    "test_bal_norm_idx = normal_idx[TRAIN_NORMAL + VAL_NORM :\n",
    "                               TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL]\n",
    "\n",
    "# Test imbalanced ~ 4:1\n",
    "TEST_IMB_NORM = min(800, n_normal - (TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL))\n",
    "test_imb_norm_idx = normal_idx[TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL :\n",
    "                               TRAIN_NORMAL + VAL_NORM + TEST_NORM_BAL + TEST_IMB_NORM]\n",
    "test_imb_anom_idx = test_bal_anom_idx  # chung anom để so công bằng\n",
    "\n",
    "def take(idx):\n",
    "    return X_all[idx], y[idx]\n",
    "\n",
    "X_train, y_train = take(train_norm_idx)           # toàn 0\n",
    "X_val   = np.vstack([X_all[val_norm_idx], X_all[val_anom_idx]])\n",
    "y_val   = np.hstack([np.zeros(len(val_norm_idx), dtype=int),\n",
    "                     np.ones (len(val_anom_idx), dtype=int)])\n",
    "\n",
    "X_test_bal = np.vstack([X_all[test_bal_norm_idx], X_all[test_bal_anom_idx]])\n",
    "y_test_bal = np.hstack([np.zeros(len(test_bal_norm_idx), dtype=int),\n",
    "                        np.ones (len(test_bal_anom_idx), dtype=int)])\n",
    "\n",
    "X_test_imb = np.vstack([X_all[test_imb_norm_idx], X_all[test_imb_anom_idx]])\n",
    "y_test_imb = np.hstack([np.zeros(len(test_imb_norm_idx), dtype=int),\n",
    "                        np.ones (len(test_imb_anom_idx), dtype=int)])\n",
    "\n",
    "print(\"\\n--- Split summary (auto) ---\")\n",
    "print(f\"Train normal size          : {X_train.shape[0]}\")\n",
    "print(f\"VAL balanced (norm/anom)   : {len(val_norm_idx)} / {len(val_anom_idx)}\")\n",
    "print(f\"TEST balanced (norm/anom)  : {len(test_bal_norm_idx)} / {len(test_bal_anom_idx)}\")\n",
    "print(f\"TEST imbalanced (norm/anom): {len(test_imb_norm_idx)} / {len(test_imb_anom_idx)}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Define GAN (logits + BCEWithLogits)\n",
    "# ------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 256), nn.ReLU(),\n",
    "            nn.Linear(256, output_dim)  # linear vì features đã z-score\n",
    "        )\n",
    "    def forward(self, z): return self.net(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 1)  # logits (không Sigmoid)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "latent_dim = 16\n",
    "G = Generator(latent_dim, input_dim).to(device)\n",
    "D = Discriminator(input_dim).to(device)\n",
    "\n",
    "bce_logits = nn.BCEWithLogitsLoss()\n",
    "opt_g = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "opt_d = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Train GAN (ONLY normal)\n",
    "# ------------------------------\n",
    "batch_size = 128\n",
    "epochs     = 60\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.from_numpy(X_train)),\n",
    "    batch_size=batch_size, shuffle=True, drop_last=False\n",
    ")\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    G.train(); D.train()\n",
    "    ep_d = ep_g = 0.0; steps = 0\n",
    "    for (real_batch,) in train_loader:\n",
    "        real_batch = real_batch.to(device)\n",
    "        bsz = real_batch.size(0)\n",
    "\n",
    "        # noise nhỏ vào input của D để tránh overfit\n",
    "        real_noisy = real_batch + 0.01 * torch.randn_like(real_batch)\n",
    "\n",
    "        # ---- Train D ----\n",
    "        opt_d.zero_grad()\n",
    "        z = torch.randn(bsz, latent_dim, device=device)\n",
    "        fake_batch = G(z).detach()\n",
    "\n",
    "        # label smoothing cho real\n",
    "        real_labels = torch.full((bsz, 1), 0.9, device=device)\n",
    "        fake_labels = torch.zeros(bsz, 1, device=device)\n",
    "\n",
    "        d_real_logits = D(real_noisy)\n",
    "        d_fake_logits = D(fake_batch)\n",
    "\n",
    "        d_loss = bce_logits(d_real_logits, real_labels) + bce_logits(d_fake_logits, fake_labels)\n",
    "        d_loss.backward(); opt_d.step()\n",
    "\n",
    "        # ---- Train G ----\n",
    "        opt_g.zero_grad()\n",
    "        z = torch.randn(bsz, latent_dim, device=device)\n",
    "        gen_batch = G(z)\n",
    "        g_loss = bce_logits(D(gen_batch), torch.ones(bsz, 1, device=device))\n",
    "        g_loss.backward(); opt_g.step()\n",
    "\n",
    "        ep_d += d_loss.item(); ep_g += g_loss.item(); steps += 1\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:3d}/{epochs} | D: {ep_d/steps:.4f} | G: {ep_g/steps:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 5) Scoring (1 - sigmoid(logits))\n",
    "# ------------------------------\n",
    "@torch.no_grad()\n",
    "def disc_scores(x_np: np.ndarray) -> np.ndarray:\n",
    "    X_t = torch.from_numpy(x_np).to(device)\n",
    "    D.eval()\n",
    "    logits = D(X_t).cpu().numpy().reshape(-1)\n",
    "    probs  = 1.0 / (1.0 + np.exp(-logits))   # sigmoid\n",
    "    return 1.0 - probs                       # higher => more anomalous\n",
    "\n",
    "# ------------------------------\n",
    "# 6) Threshold selection (manual / f1 / p_at)\n",
    "# ------------------------------\n",
    "MODE = \"manual\"    # \"manual\" | \"f1\" | \"p_at\"\n",
    "THR_MANUAL = 0.60  # <-- tự đặt ngưỡng theo kinh nghiệm/target (0..1)\n",
    "TARGET_P   = 0.60  # dùng khi MODE=\"p_at\"\n",
    "\n",
    "val_scores = disc_scores(X_val)\n",
    "\n",
    "def best_f1_threshold(y_true, scores, percentiles=np.linspace(50, 99.5, 200)):\n",
    "    thrs = np.percentile(scores, percentiles)\n",
    "    best_f1, best_thr = -1.0, None\n",
    "    for t in thrs:\n",
    "        y_pred = (scores >= t).astype(int)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, labels=[0,1], average=None, zero_division=0\n",
    "        )\n",
    "        if f1[1] > best_f1:\n",
    "            best_f1, best_thr = float(f1[1]), float(t)\n",
    "    return best_thr, best_f1\n",
    "\n",
    "def threshold_for_precision(y_true, scores, target_p=0.60):\n",
    "    p, r, thr = precision_recall_curve(y_true, scores)\n",
    "    # thr có độ dài len(p)-1\n",
    "    idx = np.where(p[:-1] >= target_p)[0]\n",
    "    if len(idx) == 0:\n",
    "        # fallback: percentile 95\n",
    "        return float(np.percentile(scores, 95)), float(p[1] if len(p)>1 else 0.0), float(r[1] if len(r)>1 else 0.0)\n",
    "    i = idx[0]\n",
    "    return float(thr[i]), float(p[i]), float(r[i])\n",
    "\n",
    "if MODE == \"manual\":\n",
    "    thr = float(THR_MANUAL)\n",
    "    # kiểm tra percentile của thr trên VAL để hình dung độ “khắc nghiệt”\n",
    "    pct = (val_scores <= thr).mean() * 100.0\n",
    "    print(f\"\\n[VAL] Manual threshold selected: thr={thr:.6f} (~percentile {pct:.2f}%)\")\n",
    "elif MODE == \"f1\":\n",
    "    thr, best_f1 = best_f1_threshold(y_val, val_scores)\n",
    "    print(f\"\\n[VAL balanced] Best F1(Class 1)={best_f1:.3f} at threshold={thr:.6f}\")\n",
    "else:  # MODE == \"p_at\"\n",
    "    thr, p_at, r_at = threshold_for_precision(y_val, val_scores, TARGET_P)\n",
    "    print(f\"\\n[VAL balanced] Threshold for Precision≥{TARGET_P:.2f}: thr={thr:.6f} (P={p_at:.3f}, R={r_at:.3f})\")\n",
    "\n",
    "# ------------------------------\n",
    "# 7) Evaluate on TEST sets\n",
    "# ------------------------------\n",
    "def evaluate(name: str, X_np: np.ndarray, y_true: np.ndarray, thr: float):\n",
    "    scores = disc_scores(X_np)\n",
    "    y_pred = (scores >= thr).astype(int)\n",
    "    print(f\"\\n===== {name} @thr={thr:.6f} =====\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "    print(\"ROC AUC (scores):\", roc_auc_score(y_true, scores))\n",
    "\n",
    "evaluate(\"TEST Balanced\",   X_test_bal, y_test_bal, thr)\n",
    "evaluate(\"TEST Imbalanced\", X_test_imb, y_test_imb, thr)\n",
    "\n",
    "# ------------------------------\n",
    "# 8) (Optional) Thử nhanh vài ngưỡng để so sánh\n",
    "# ------------------------------\n",
    "candidates = [0.30, 0.40, 0.50, 0.60, 0.70]\n",
    "print(\"\\n>>> Quick sweep on a few manual thresholds:\")\n",
    "for t in candidates:\n",
    "    print(f\"\\n-- Try thr={t:.3f} on TEST Balanced --\")\n",
    "    evaluate(\"TEST Balanced\", X_test_bal, y_test_bal, t)\n",
    "    print(f\"\\n-- Try thr={t:.3f} on TEST Imbalanced --\")\n",
    "    evaluate(\"TEST Imbalanced\", X_test_imb, y_test_imb, t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
