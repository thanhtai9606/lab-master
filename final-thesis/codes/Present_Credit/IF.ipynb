{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ead8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số dòng: 284807\n",
      "Phân phối nhãn Class:\n",
      " Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "Tỷ lệ (%):\n",
      " Class\n",
      "0    99.827251\n",
      "1     0.172749\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Normal: 284315 | Anomaly: 492\n",
      "\n",
      "--- Split summary (auto) ---\n",
      "Train normal size          : 8000\n",
      "VAL balanced (norm/anom)   : 150 / 150\n",
      "TEST balanced (norm/anom)  : 200 / 200\n",
      "TEST imbalanced (norm/anom): 800 / 200\n",
      "\n",
      "[VAL balanced] Best F1(Class 1)=0.895 at threshold=0.434747\n",
      "\n",
      "===== TEST Balanced (200/200) @thr=0.434747 =====\n",
      "Confusion Matrix:\n",
      " [[181  19]\n",
      " [ 22 178]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8916    0.9050    0.8983       200\n",
      "           1     0.9036    0.8900    0.8967       200\n",
      "\n",
      "    accuracy                         0.8975       400\n",
      "   macro avg     0.8976    0.8975    0.8975       400\n",
      "weighted avg     0.8976    0.8975    0.8975       400\n",
      "\n",
      "ROC AUC (scores): 0.939375\n",
      "\n",
      "===== TEST Imbalanced (800/200) @thr=0.434747 =====\n",
      "Confusion Matrix:\n",
      " [[718  82]\n",
      " [ 22 178]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9703    0.8975    0.9325       800\n",
      "           1     0.6846    0.8900    0.7739       200\n",
      "\n",
      "    accuracy                         0.8960      1000\n",
      "   macro avg     0.8274    0.8938    0.8532      1000\n",
      "weighted avg     0.9131    0.8960    0.9008      1000\n",
      "\n",
      "ROC AUC (scores): 0.9406812499999999\n",
      "\n",
      ">>> Quick sweep on percentile-based thresholds (from VAL):\n",
      "\n",
      "-- Try thr=0.610805 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced (200/200) @thr=0.610805 =====\n",
      "Confusion Matrix:\n",
      " [[199   1]\n",
      " [138  62]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5905    0.9950    0.7412       200\n",
      "           1     0.9841    0.3100    0.4715       200\n",
      "\n",
      "    accuracy                         0.6525       400\n",
      "   macro avg     0.7873    0.6525    0.6063       400\n",
      "weighted avg     0.7873    0.6525    0.6063       400\n",
      "\n",
      "ROC AUC (scores): 0.939375\n",
      "\n",
      "-- Try thr=0.610805 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced (800/200) @thr=0.610805 =====\n",
      "Confusion Matrix:\n",
      " [[796   4]\n",
      " [138  62]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8522    0.9950    0.9181       800\n",
      "           1     0.9394    0.3100    0.4662       200\n",
      "\n",
      "    accuracy                         0.8580      1000\n",
      "   macro avg     0.8958    0.6525    0.6921      1000\n",
      "weighted avg     0.8697    0.8580    0.8277      1000\n",
      "\n",
      "ROC AUC (scores): 0.9406812499999999\n",
      "\n",
      "-- Try thr=0.634035 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced (200/200) @thr=0.634035 =====\n",
      "Confusion Matrix:\n",
      " [[199   1]\n",
      " [151  49]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5686    0.9950    0.7236       200\n",
      "           1     0.9800    0.2450    0.3920       200\n",
      "\n",
      "    accuracy                         0.6200       400\n",
      "   macro avg     0.7743    0.6200    0.5578       400\n",
      "weighted avg     0.7743    0.6200    0.5578       400\n",
      "\n",
      "ROC AUC (scores): 0.939375\n",
      "\n",
      "-- Try thr=0.634035 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced (800/200) @thr=0.634035 =====\n",
      "Confusion Matrix:\n",
      " [[800   0]\n",
      " [151  49]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8412    1.0000    0.9138       800\n",
      "           1     1.0000    0.2450    0.3936       200\n",
      "\n",
      "    accuracy                         0.8490      1000\n",
      "   macro avg     0.9206    0.6225    0.6537      1000\n",
      "weighted avg     0.8730    0.8490    0.8097      1000\n",
      "\n",
      "ROC AUC (scores): 0.9406812499999999\n",
      "\n",
      "-- Try thr=0.658370 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced (200/200) @thr=0.658370 =====\n",
      "Confusion Matrix:\n",
      " [[200   0]\n",
      " [170  30]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5405    1.0000    0.7018       200\n",
      "           1     1.0000    0.1500    0.2609       200\n",
      "\n",
      "    accuracy                         0.5750       400\n",
      "   macro avg     0.7703    0.5750    0.4813       400\n",
      "weighted avg     0.7703    0.5750    0.4813       400\n",
      "\n",
      "ROC AUC (scores): 0.939375\n",
      "\n",
      "-- Try thr=0.658370 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced (800/200) @thr=0.658370 =====\n",
      "Confusion Matrix:\n",
      " [[800   0]\n",
      " [170  30]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8247    1.0000    0.9040       800\n",
      "           1     1.0000    0.1500    0.2609       200\n",
      "\n",
      "    accuracy                         0.8300      1000\n",
      "   macro avg     0.9124    0.5750    0.5824      1000\n",
      "weighted avg     0.8598    0.8300    0.7753      1000\n",
      "\n",
      "ROC AUC (scores): 0.9406812499999999\n",
      "\n",
      "-- Try thr=0.689973 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced (200/200) @thr=0.689973 =====\n",
      "Confusion Matrix:\n",
      " [[200   0]\n",
      " [184  16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5208    1.0000    0.6849       200\n",
      "           1     1.0000    0.0800    0.1481       200\n",
      "\n",
      "    accuracy                         0.5400       400\n",
      "   macro avg     0.7604    0.5400    0.4165       400\n",
      "weighted avg     0.7604    0.5400    0.4165       400\n",
      "\n",
      "ROC AUC (scores): 0.939375\n",
      "\n",
      "-- Try thr=0.689973 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced (800/200) @thr=0.689973 =====\n",
      "Confusion Matrix:\n",
      " [[800   0]\n",
      " [184  16]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8130    1.0000    0.8969       800\n",
      "           1     1.0000    0.0800    0.1481       200\n",
      "\n",
      "    accuracy                         0.8160      1000\n",
      "   macro avg     0.9065    0.5400    0.5225      1000\n",
      "weighted avg     0.8504    0.8160    0.7471      1000\n",
      "\n",
      "ROC AUC (scores): 0.9406812499999999\n",
      "\n",
      "-- Try thr=0.698191 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced (200/200) @thr=0.698191 =====\n",
      "Confusion Matrix:\n",
      " [[200   0]\n",
      " [189  11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5141    1.0000    0.6791       200\n",
      "           1     1.0000    0.0550    0.1043       200\n",
      "\n",
      "    accuracy                         0.5275       400\n",
      "   macro avg     0.7571    0.5275    0.3917       400\n",
      "weighted avg     0.7571    0.5275    0.3917       400\n",
      "\n",
      "ROC AUC (scores): 0.939375\n",
      "\n",
      "-- Try thr=0.698191 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced (800/200) @thr=0.698191 =====\n",
      "Confusion Matrix:\n",
      " [[800   0]\n",
      " [189  11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8089    1.0000    0.8944       800\n",
      "           1     1.0000    0.0550    0.1043       200\n",
      "\n",
      "    accuracy                         0.8110      1000\n",
      "   macro avg     0.9044    0.5275    0.4993      1000\n",
      "weighted avg     0.8471    0.8110    0.7363      1000\n",
      "\n",
      "ROC AUC (scores): 0.9406812499999999\n",
      "\n",
      "-- Try thr=0.736304 on TEST Balanced --\n",
      "\n",
      "===== TEST Balanced (200/200) @thr=0.736304 =====\n",
      "Confusion Matrix:\n",
      " [[200   0]\n",
      " [198   2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5025    1.0000    0.6689       200\n",
      "           1     1.0000    0.0100    0.0198       200\n",
      "\n",
      "    accuracy                         0.5050       400\n",
      "   macro avg     0.7513    0.5050    0.3443       400\n",
      "weighted avg     0.7513    0.5050    0.3443       400\n",
      "\n",
      "ROC AUC (scores): 0.939375\n",
      "\n",
      "-- Try thr=0.736304 on TEST Imbalanced --\n",
      "\n",
      "===== TEST Imbalanced (800/200) @thr=0.736304 =====\n",
      "Confusion Matrix:\n",
      " [[800   0]\n",
      " [198   2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8016    1.0000    0.8899       800\n",
      "           1     1.0000    0.0100    0.0198       200\n",
      "\n",
      "    accuracy                         0.8020      1000\n",
      "   macro avg     0.9008    0.5050    0.4548      1000\n",
      "weighted avg     0.8413    0.8020    0.7159      1000\n",
      "\n",
      "ROC AUC (scores): 0.9406812499999999\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Isolation Forest (creditcard.csv) with manual/F1/Precision threshold\n",
    "# - Splits: TrainN=20k normal, VAL 250/250, TEST Balanced 200/200, TEST Imbalanced 10k/200\n",
    "# - Scale fit on train normal only\n",
    "# - Scores = -score_samples (cao hơn => bất thường hơn)\n",
    "# ==========================================\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    precision_recall_fscore_support, precision_recall_curve\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 0) Seeds\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Load\n",
    "# ------------------------------\n",
    "csv_path = \"../creditcard.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "assert \"Class\" in df.columns\n",
    "X_df = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"].astype(int).to_numpy()\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Splits (no overlap), same as VAE/GAN\n",
    "# ------------------------------\n",
    "normal_idx = np.where(y==0)[0]; anom_idx = np.where(y==1)[0]\n",
    "rng = np.random.default_rng(SEED); rng.shuffle(normal_idx); rng.shuffle(anom_idx)\n",
    "\n",
    "TR_N, VAL_N, VAL_A, TESTB_N, TESTB_A, TESTI_N = 20000, 250, 250, 200, 200, 10000\n",
    "assert len(anom_idx) >= (VAL_A + TESTB_A), \"Không đủ anomaly cho VAL/TESTB.\"\n",
    "\n",
    "# Bảo đảm còn đủ normal cho TESTI & train\n",
    "max_train_normal = len(normal_idx) - (VAL_N + TESTB_N + TESTI_N)\n",
    "if max_train_normal < 1000:\n",
    "    TESTI_N = max(2000, len(normal_idx) - (VAL_N + TESTB_N + 1000))\n",
    "    max_train_normal = len(normal_idx) - (VAL_N + TESTB_N + TESTI_N)\n",
    "TRAIN_N = max(5000, min(TR_N, max_train_normal))\n",
    "\n",
    "# Cắt chỉ số\n",
    "ptr_n=0; ptr_a=0\n",
    "trn_n = normal_idx[ptr_n:ptr_n+TRAIN_N]; ptr_n+=TRAIN_N\n",
    "val_n = normal_idx[ptr_n:ptr_n+VAL_N];   ptr_n+=VAL_N\n",
    "tstb_n= normal_idx[ptr_n:ptr_n+TESTB_N]; ptr_n+=TESTB_N\n",
    "tsti_n= normal_idx[ptr_n:ptr_n+TESTI_N]; ptr_n+=TESTI_N\n",
    "\n",
    "val_a = anom_idx[ptr_a:ptr_a+VAL_A]; ptr_a+=VAL_A\n",
    "tstb_a= anom_idx[ptr_a:ptr_a+TESTB_A]; ptr_a+=TESTB_A\n",
    "tsti_a= tstb_a  # dùng chung anomaly với test balanced\n",
    "\n",
    "def take(idxs): return X_df.iloc[idxs].to_numpy().astype(np.float32), y[idxs]\n",
    "X_tr_n, _ = take(trn_n)\n",
    "\n",
    "X_val = np.vstack([X_df.iloc[val_n].to_numpy(), X_df.iloc[val_a].to_numpy()]).astype(np.float32)\n",
    "y_val = np.hstack([np.zeros(len(val_n), dtype=int), np.ones(len(val_a), dtype=int)])\n",
    "\n",
    "X_tstb = np.vstack([X_df.iloc[tstb_n].to_numpy(), X_df.iloc[tstb_a].to_numpy()]).astype(np.float32)\n",
    "y_tstb = np.hstack([np.zeros(len(tstb_n), dtype=int), np.ones(len(tstb_a), dtype=int)])\n",
    "\n",
    "X_tsti = np.vstack([X_df.iloc[tsti_n].to_numpy(), X_df.iloc[tsti_a].to_numpy()]).astype(np.float32)\n",
    "y_tsti = np.hstack([np.zeros(len(tsti_n), dtype=int), np.ones(len(tsti_a), dtype=int)])\n",
    "\n",
    "print(f\"TrainN={len(trn_n)}, Val={len(val_n)}/{len(val_a)}, TestB={len(tstb_n)}/{len(tstb_a)}, TestI={len(tsti_n)}/{len(tsti_a)}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 3) Scale (fit on train normal only)\n",
    "# ------------------------------\n",
    "scaler = StandardScaler().fit(X_tr_n)\n",
    "def z(x): return scaler.transform(x).astype(np.float32)\n",
    "X_tr_n = z(X_tr_n); X_val = z(X_val); X_tstb = z(X_tstb); X_tsti = z(X_tsti)\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Fit Isolation Forest on normal only\n",
    "# ------------------------------\n",
    "clf = IsolationForest(\n",
    "    n_estimators=400,\n",
    "    max_samples=512,\n",
    "    contamination=\"auto\",  # ta tự đặt ngưỡng bằng scores\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(X_tr_n)\n",
    "\n",
    "def anomaly_score(model, X):\n",
    "    # score_samples: higher => more normal -> đảo dấu để high = anomalous\n",
    "    return -model.score_samples(X)\n",
    "\n",
    "val_scores = anomaly_score(clf, X_val)\n",
    "\n",
    "# ------------------------------\n",
    "# 5) Threshold selection\n",
    "# ------------------------------\n",
    "MODE = \"f1\"        # \"manual\" | \"f1\" | \"p_at\"\n",
    "THR_MANUAL = float(np.percentile(val_scores, 95))  # gợi ý khi manual\n",
    "TARGET_P   = 0.60  # Precision target khi MODE=\"p_at\"\n",
    "\n",
    "def best_f1_threshold(y_true, scores, percentiles=np.linspace(50, 99.5, 200)):\n",
    "    ths = np.percentile(scores, percentiles)\n",
    "    best_f1, best_thr = -1.0, None\n",
    "    for t in ths:\n",
    "        yhat = (scores >= t).astype(int)\n",
    "        _, _, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, yhat, labels=[0,1], average=None, zero_division=0\n",
    "        )\n",
    "        if f1[1] > best_f1:\n",
    "            best_f1, best_thr = float(f1[1]), float(t)\n",
    "    return best_thr, best_f1\n",
    "\n",
    "def threshold_for_precision(y_true, scores, target_p=0.60):\n",
    "    p, r, thr = precision_recall_curve(y_true, scores)\n",
    "    # thr dài = len(p)-1\n",
    "    idx = np.where(p[:-1] >= target_p)[0]\n",
    "    if len(idx) == 0:\n",
    "        # fallback: 95th percentile nếu không đạt precision target trên VAL\n",
    "        return float(np.percentile(scores, 95)), float(p[1] if len(p)>1 else 0.0), float(r[1] if len(r)>1 else 0.0)\n",
    "    i = idx[0]\n",
    "    return float(thr[i]), float(p[i]), float(r[i])\n",
    "\n",
    "if MODE == \"manual\":\n",
    "    thr = float(THR_MANUAL)\n",
    "    pct = (val_scores <= thr).mean() * 100.0\n",
    "    print(f\"\\n[VAL] Manual threshold selected: thr={thr:.6f} (~percentile {pct:.2f}%)\")\n",
    "elif MODE == \"f1\":\n",
    "    thr, f1v = best_f1_threshold(y_val, val_scores)\n",
    "    print(f\"\\n[VAL balanced] Best F1(Class 1)={f1v:.3f} at threshold={thr:.6f}\")\n",
    "else:\n",
    "    thr, p_at, r_at = threshold_for_precision(y_val, val_scores, TARGET_P)\n",
    "    print(f\"\\n[VAL balanced] Threshold for Precision≥{TARGET_P:.2f}: thr={thr:.6f} (P={p_at:.3f}, R={r_at:.3f})\")\n",
    "\n",
    "# ------------------------------\n",
    "# 6) Evaluate\n",
    "# ------------------------------\n",
    "def evaluate(name, X, y, thr):\n",
    "    s = anomaly_score(clf, X); yhat = (s >= thr).astype(int)\n",
    "    print(f\"\\n===== {name} @thr={thr:.6f} =====\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y, yhat))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y, yhat, digits=4))\n",
    "    print(\"ROC AUC (scores):\", roc_auc_score(y, s))\n",
    "\n",
    "evaluate(\"TEST Balanced (200/200)\",     X_tstb, y_tstb, thr)\n",
    "evaluate(\"TEST Imbalanced (10000/200)\", X_tsti, y_tsti, thr)\n",
    "\n",
    "# ------------------------------\n",
    "# 7) Quick sweep vài percentile để quan sát\n",
    "# ------------------------------\n",
    "cands = [80, 90, 92.5, 95, 97.5, 99]\n",
    "print(\"\\n>>> Quick sweep on percentile-based thresholds (from VAL):\")\n",
    "for p in cands:\n",
    "    t = float(np.percentile(val_scores, p))\n",
    "    print(f\"\\n-- Try thr={t:.6f} (pctl={p}) on TEST Balanced --\")\n",
    "    evaluate(\"TEST Balanced (200/200)\", X_tstb, y_tstb, t)\n",
    "    print(f\"\\n-- Try thr={t:.6f} (pctl={p}) on TEST Imbalanced --\")\n",
    "    evaluate(\"TEST Imbalanced (10000/200)\", X_tsti, y_tsti, t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
