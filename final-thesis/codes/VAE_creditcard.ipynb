{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision scikit-learn pandas matplotlib kaggle imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/homebrew/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /opt/homebrew/lib/python3.11/site-packages (from imbalanced-learn) (2.3.0)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /opt/homebrew/lib/python3.11/site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /opt/homebrew/lib/python3.11/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /opt/homebrew/lib/python3.11/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from imbalanced-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Chuẩn hóa cột 'Amount' và 'Time'\n",
    "scaler = StandardScaler()\n",
    "data['Amount_scaled'] = scaler.fit_transform(data[['Amount']])\n",
    "data['Time_scaled'] = scaler.fit_transform(data[['Time']])\n",
    "\n",
    "# Xóa các cột 'Class', 'Amount', và 'Time' chưa chuẩn hóa\n",
    "X = data.drop(columns=['Class', 'Amount', 'Time'])\n",
    "\n",
    "# Thêm cột 'Amount_scaled' và 'Time_scaled'\n",
    "X['Amount'] = data['Amount_scaled']\n",
    "X['Time'] = data['Time_scaled']\n",
    "\n",
    "# Nhãn dữ liệu\n",
    "y = data['Class']\n",
    "\n",
    "\n",
    "\n",
    "# # Sử dụng SMOTE để cân bằng dữ liệu\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# # Sau đó chia dữ liệu cân bằng thành tập huấn luyện và kiểm tra\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Chuyển đổi sang tensor cho PyTorch\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2_mu = nn.Linear(32, latent_dim)\n",
    "        self.fc2_logvar = nn.Linear(32, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, 32)\n",
    "        self.fc4 = nn.Linear(32, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = torch.relu(self.fc1(x))\n",
    "        return self.fc2_mu(h), self.fc2_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = torch.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# Khởi tạo mô hình VAE\n",
    "input_dim = X_train.shape[1]\n",
    "latent_dim = 2\n",
    "model = VAE(input_dim, latent_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 33.78617138684198\n",
      "Epoch 2, Loss: 33.128066183963035\n",
      "Epoch 3, Loss: 32.972622450755914\n",
      "Epoch 4, Loss: 32.90775522989947\n",
      "Epoch 5, Loss: 32.84084841091932\n",
      "Epoch 6, Loss: 32.793813531765906\n",
      "Epoch 7, Loss: 32.778785428310435\n",
      "Epoch 8, Loss: 32.75519574347901\n",
      "Epoch 9, Loss: 32.74174311500025\n",
      "Epoch 10, Loss: 32.728300708225866\n",
      "Epoch 11, Loss: 32.72158245245807\n",
      "Epoch 12, Loss: 32.71143355874878\n",
      "Epoch 13, Loss: 32.71215732849626\n",
      "Epoch 14, Loss: 32.715689786684024\n",
      "Epoch 15, Loss: 32.7006563610524\n",
      "Epoch 16, Loss: 32.702853693111685\n",
      "Epoch 17, Loss: 32.713991340513815\n",
      "Epoch 18, Loss: 32.68417221139989\n",
      "Epoch 19, Loss: 39.98798231488902\n",
      "Epoch 20, Loss: 32.70492088912063\n"
     ]
    }
   ],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "epochs = 20\n",
    "model.train()\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, X_train_tensor), batch_size=32, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    for x, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(x)\n",
    "        loss = loss_function(recon_batch, x, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {train_loss / len(train_loader.dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Reconstruction_Loss  Predicted_Anomaly  Actual_Label\n",
      "0             73.117935                  1             1\n",
      "9              2.636425                  1             0\n",
      "31             2.277299                  1             0\n",
      "32           120.569809                  1             0\n",
      "41             2.604541                  1             0\n",
      "Missed fraud cases:\n",
      "       Reconstruction_Loss  Predicted_Anomaly  Actual_Label\n",
      "8379              0.974470                  0             1\n",
      "10279             0.963051                  0             1\n",
      "17388             0.759210                  0             1\n",
      "22797             1.869860                  0             1\n",
      "30129             1.932633                  0             1\n"
     ]
    }
   ],
   "source": [
    "# Đặt mô hình vào chế độ đánh giá\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_pred, _, _ = model(X_test_tensor)\n",
    "    reconstruction_loss = torch.mean((X_test_tensor - X_test_pred) ** 2, dim=1).numpy()\n",
    "\n",
    "# Thiết lập ngưỡng phát hiện bất thường\n",
    "threshold = np.percentile(reconstruction_loss, 95)  # Ngưỡng 95% của lỗi tái tạo\n",
    "\n",
    "# Gán nhãn dự đoán dựa trên ngưỡng\n",
    "y_pred = (reconstruction_loss > threshold).astype(int)  # 1 là bất thường, 0 là bình thường\n",
    "\n",
    "# So sánh kết quả với nhãn thực tế\n",
    "import pandas as pd\n",
    "\n",
    "# Tạo DataFrame chứa kết quả dự đoán và nhãn thực tế\n",
    "results_df = pd.DataFrame({\n",
    "    'Reconstruction_Loss': reconstruction_loss,   # Lỗi tái tạo từ VAE\n",
    "    'Predicted_Anomaly': y_pred,                  # 1 là bất thường, 0 là bình thường\n",
    "    'Actual_Label': y_test.values                 # Nhãn thực tế từ dữ liệu\n",
    "})\n",
    "\n",
    "# Hiển thị các giao dịch mà mô hình đánh dấu là gian lận và so sánh với nhãn thực tế\n",
    "fraud_cases = results_df[results_df['Predicted_Anomaly'] == 1]  # Các giao dịch được dự đoán là gian lận\n",
    "print(fraud_cases.head())  # Hiển thị một số giao dịch bị dự đoán là gian lận\n",
    "\n",
    "# Hiển thị các giao dịch mà mô hình bỏ sót (thực tế là gian lận nhưng không được dự đoán)\n",
    "missed_fraud_cases = results_df[(results_df['Predicted_Anomaly'] == 0) & (results_df['Actual_Label'] == 1)]\n",
    "print(\"Missed fraud cases:\")\n",
    "print(missed_fraud_cases.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[54100  2764]\n",
      " [   13    85]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     56864\n",
      "           1       0.03      0.87      0.06        98\n",
      "\n",
      "    accuracy                           0.95     56962\n",
      "   macro avg       0.51      0.91      0.52     56962\n",
      "weighted avg       1.00      0.95      0.97     56962\n",
      "\n",
      "ROC AUC Score: 0.9093698678120657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# So sánh kết quả với nhãn thực tế\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Vẽ biểu đồ phân phối của reconstruction_loss\u001b[39;00m\n\u001b[32m      5\u001b[39m plt.figure(figsize=(\u001b[32m14\u001b[39m, \u001b[32m8\u001b[39m))\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# Vẽ biểu đồ phân phối của reconstruction_loss\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.hist(reconstruction_loss[y_test == 0], bins=50, alpha=0.6, label='Non-Fraud')\n",
    "plt.hist(reconstruction_loss[y_test == 1], bins=50, alpha=0.6, label='Fraud')\n",
    "plt.axvline(threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Loss by Class')\n",
    "plt.xlabel('Reconstruction Loss')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Fraud Cases:\n",
      "    Reconstruction_Loss  Predicted_Anomaly  Actual_Label\n",
      "0             74.084999                  1             1\n",
      "9              2.557303                  1             0\n",
      "31             2.191410                  1             0\n",
      "32           119.346313                  1             0\n",
      "41             2.830609                  1             0\n",
      "False Positives (Predicted Fraud, but Actually Non-Fraud):\n",
      "    Reconstruction_Loss  Predicted_Anomaly  Actual_Label\n",
      "9              2.557303                  1             0\n",
      "31             2.191410                  1             0\n",
      "32           119.346313                  1             0\n",
      "41             2.830609                  1             0\n",
      "44             2.624180                  1             0\n",
      "False Negatives (Predicted Non-Fraud, but Actually Fraud):\n",
      "       Reconstruction_Loss  Predicted_Anomaly  Actual_Label\n",
      "8379              0.808348                  0             1\n",
      "10279             0.841183                  0             1\n",
      "17388             0.703998                  0             1\n",
      "22797             1.552286                  0             1\n",
      "30129             1.781046                  0             1\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị các giao dịch được dự đoán là gian lận\n",
    "fraud_cases = results_df[results_df['Predicted_Anomaly'] == 1]\n",
    "print(\"Predicted Fraud Cases:\")\n",
    "print(fraud_cases.head())\n",
    "\n",
    "# Hiển thị các giao dịch mà mô hình dự đoán sai (False Positives và False Negatives)\n",
    "false_positives = results_df[(results_df['Predicted_Anomaly'] == 1) & (results_df['Actual_Label'] == 0)]\n",
    "false_negatives = results_df[(results_df['Predicted_Anomaly'] == 0) & (results_df['Actual_Label'] == 1)]\n",
    "\n",
    "print(\"False Positives (Predicted Fraud, but Actually Non-Fraud):\")\n",
    "print(false_positives.head())\n",
    "\n",
    "print(\"False Negatives (Predicted Non-Fraud, but Actually Fraud):\")\n",
    "print(false_negatives.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
